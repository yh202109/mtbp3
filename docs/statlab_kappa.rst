#############
StatLab/Cohen's Kappa for inter-rater reliability
#############

*************
Background
*************

Cohen's kappa is a statistic used for describing, summarizing, estimating and testing inter-ratter consistency. 


*************
Notation
*************

For two categories rating, assume :math:`Y_{r,i} \in \{A,B\}` for rater :math:`r=1,2` and sample index :math:`i = 1, \ldots, n.
